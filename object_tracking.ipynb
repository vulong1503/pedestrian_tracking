{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22eda5de",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "import configparser\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94151bdc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def convert_to_yolo_format(bb,img_width,img_height):\n",
    "    x_center=bb['bb_left']+ (bb['bb_width']/2)\n",
    "    y_center=bb['bb_top'] + (bb['bb_height']/2)\n",
    "\n",
    "    x_center/=img_width\n",
    "    y_center/=img_height\n",
    "    bb_width_normalized=bb['bb_width']/img_width\n",
    "    bb_height_normalized=bb['bb_height']/img_height\n",
    "\n",
    "    x_center=max(min(x_center,1),0)\n",
    "    y_center = max(min(y_center, 1), 0)\n",
    "    bb_width_normalized = max(min(bb_width_normalized,1),0)\n",
    "    bb_height_normalized= max(min(bb_height_normalized,1),0)\n",
    "    return  (x_center,y_center,bb_width_normalized,bb_height_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c447839",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    config=configparser.ConfigParser()\n",
    "    config.read(os.path.join(folder_path,'seqinfo.ini'))\n",
    "    img_width=int(config['Sequence']['imWidth'])\n",
    "    img_height=int(config['Sequence']['imHeight'])\n",
    "    #load groud truth data\n",
    "    gt_path=os.path.join(folder_path,'det/det.txt')\n",
    "    gt_data=pd.read_csv(gt_path,header=None,names=['frame','id','bb_left', 'bb_top','bb_width','bb_height','conf','class','visibility'])\n",
    "    labels_folder=os.path.join(folder_path,'labels')\n",
    "    os.makedirs(labels_folder,exist_ok=True)\n",
    "\n",
    "    for frame_number in gt_data['frame'].unique():\n",
    "        frame_data=gt_data[gt_data['frame']==frame_number]\n",
    "        label_file=os.path.join(labels_folder,f'{frame_number:06d}.txt')\n",
    "        with open(label_file,'w') as file:\n",
    "            for _,row in frame_data.iterrows():\n",
    "                yolo_bb=convert_to_yolo_format(row,img_width,img_height)\n",
    "                file.write(f'0 {yolo_bb[0]} {yolo_bb[1]} {yolo_bb[2]} {yolo_bb[3]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152bcd3c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_all_folders(base_directory):\n",
    "    for folder_name in tqdm(os.listdir(base_directory)):\n",
    "        folder_path=os.path.join(base_directory,folder_name)\n",
    "\n",
    "        if 'FRCNN' not in folder_name:\n",
    "            os.system(f'rm -rf {folder_path}')\n",
    "        if os.path.isdir(folder_path):\n",
    "            process_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7661193",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:13<00:00,  1.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:16<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "process_all_folders('MOT17/train')\n",
    "process_all_folders('MOT17/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0e1089",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def rename_and_move_files(src_folder,dst_folder,folder_name,file_extension):\n",
    "    for file_name in os.listdir(src_folder):\n",
    "        if file_name.endswith(file_extension):\n",
    "            new_filename=f'{folder_name}_{file_name}'\n",
    "            shutil.move(os.path.join(src_folder,file_name), os.path.join(dst_folder,new_filename))\n",
    "\n",
    "def move_files_all_folders(base_directory):\n",
    "    images_dir=os.path.join(base_directory,'images')\n",
    "    labels_dir=os.path.join(base_directory,'labels')\n",
    "    os.makedirs(images_dir,exist_ok=True)\n",
    "    os.makedirs(labels_dir,exist_ok=True)\n",
    "    for folder_name in tqdm(os.listdir(base_directory)):\n",
    "        if folder_name in ['images','labels']:\n",
    "            continue\n",
    "        folder_path=os.path.join(base_directory,folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            rename_and_move_files(os.path.join(folder_path,'img1'),images_dir,folder_name,'.jpg')\n",
    "            rename_and_move_files(os.path.join(folder_path,'labels'),labels_dir,folder_name,'.txt')\n",
    "\n",
    "def delete_subfolders ( base_directory ):\n",
    "    for folder_name in os. listdir ( base_directory ):\n",
    "        folder_path = os. path . join ( base_directory , folder_name )\n",
    "        if os. path . isdir ( folder_path ) and folder_name not in ['images','labels']:\n",
    "            shutil . rmtree ( folder_path )\n",
    "            print (f\" Deleted folder : { folder_name }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fedb4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:08<00:00,  1.04it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:10<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "move_files_all_folders('MOT17/train')\n",
    "move_files_all_folders('MOT17/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e68d1eb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Deleted folder : MOT17-02-FRCNN\n",
      " Deleted folder : MOT17-04-FRCNN\n",
      " Deleted folder : MOT17-05-FRCNN\n",
      " Deleted folder : MOT17-09-FRCNN\n",
      " Deleted folder : MOT17-10-FRCNN\n",
      " Deleted folder : MOT17-11-FRCNN\n",
      " Deleted folder : MOT17-13-FRCNN\n",
      " Deleted folder : MOT17-01-FRCNN\n",
      " Deleted folder : MOT17-03-FRCNN\n",
      " Deleted folder : MOT17-06-FRCNN\n",
      " Deleted folder : MOT17-07-FRCNN\n",
      " Deleted folder : MOT17-08-FRCNN\n",
      " Deleted folder : MOT17-12-FRCNN\n",
      " Deleted folder : MOT17-14-FRCNN\n"
     ]
    }
   ],
   "source": [
    "delete_subfolders ('MOT17/train')\n",
    "delete_subfolders ('MOT17/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ae7d60d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class_label=['object']\n",
    "data_root_dir=os.path.join(os.getcwd(),'MOT17')\n",
    "yolo_yaml_path=os.path.join(data_root_dir,'mot17_data.yml')\n",
    "data_yaml={\n",
    "    'path':data_root_dir,\n",
    "    'train':'train/images',\n",
    "    'val':'test/images',\n",
    "    'nc': len(class_label),\n",
    "    'names':class_label\n",
    "}\n",
    "with open(yolo_yaml_path,'w') as f:\n",
    "    yaml.dump(data_yaml,f,default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18af8290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AIO2023\\object_tracking_project\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "#ultralytics.checks()\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5645be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593ea379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.27 ðŸš€ Python-3.11.8 torch-2.2.1 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=e:\\AIO2023\\object_tracking_project\\MOT17\\mot17_data.yml, epochs=30, time=None, patience=100, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=models/yolo, name=yolov8s_mot17_det4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=models\\yolo\\yolov8s_mot17_det4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce GTX 1070) 8.00G total, 0.12G reserved, 0.11G allocated, 7.76G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    11135987       28.65         0.359         50.68         31.34        (1, 3, 640, 640)                    list\n",
      "    11135987       57.29         0.583         22.34         39.68        (2, 3, 640, 640)                    list\n",
      "    11135987       114.6         1.179         37.68         61.68        (4, 3, 640, 640)                    list\n",
      "    11135987       229.2         2.068         69.02           102        (8, 3, 640, 640)                    list\n",
      "    11135987       458.4         3.924         130.7         181.7       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 19 for CUDA:0 4.89G/8.00G (61%) âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\AIO2023\\object_tracking_project\\MOT17\\train\\labels... 5316 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5316/5316 [01:19<00:00, 66.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: E:\\AIO2023\\object_tracking_project\\MOT17\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\AIO2023\\object_tracking_project\\MOT17\\test\\labels... 5908 images, 11 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5919/5919 [01:53<00:00, 52.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: E:\\AIO2023\\object_tracking_project\\MOT17\\test\\labels.cache\n",
      "Plotting labels to models\\yolo\\yolov8s_mot17_det4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00044531249999999996), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mmodels\\yolo\\yolov8s_mot17_det4\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      5.07G      1.082     0.7065     0.9592        285        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:48<00:00,  1.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:34<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.888       0.82      0.908      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      5.16G     0.9907     0.5972     0.9288        342        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:08<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:51<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.879      0.812      0.898      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      5.17G      0.941     0.5589     0.9162        385        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:07<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:24<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.874      0.791      0.882      0.583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      5.16G     0.9226     0.5441     0.9123        257        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:08<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:15<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.879      0.782       0.87      0.575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30      5.15G     0.8799     0.5145      0.902        296        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:08<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:19<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.883      0.834      0.911      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      5.15G     0.8402     0.4907     0.8918        334        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:06<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:18<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.877      0.831      0.903      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      5.15G     0.8244     0.4799     0.8893        310        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:05<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:16<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.895      0.785      0.876      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      5.14G     0.7882     0.4559     0.8816        396        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:04<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:58<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.889      0.805      0.894      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      5.16G     0.7827     0.4518     0.8787        430        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:59<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:55<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.891      0.816      0.904      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30      5.17G     0.7572     0.4347     0.8734        310        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:58<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:57<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.894      0.811      0.897      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      5.14G     0.7364     0.4248     0.8701        372        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:04<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:56<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.888       0.82      0.899       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      5.16G     0.7266     0.4151      0.864        389        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:59<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:55<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.892      0.829      0.906      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      5.16G     0.7117     0.4058     0.8615        294        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:58<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:57<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.897      0.822      0.891      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      5.14G     0.7018     0.3991     0.8625        303        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:06<00:00,  1.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:58<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.894      0.822      0.901      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      5.17G     0.6937     0.3969     0.8601        338        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:11<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:00<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.897      0.805      0.902      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      5.15G     0.6753     0.3856     0.8546        317        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:04<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:55<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.896      0.809      0.898      0.632\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      5.14G     0.6688     0.3817     0.8546        303        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:01<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:56<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.895      0.808      0.904      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      5.15G     0.6577     0.3742      0.853        356        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:01<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:56<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.895      0.817      0.901      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      5.17G     0.6502     0.3694     0.8493        318        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:59<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:57<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.894      0.827      0.909      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      5.16G     0.6394     0.3627     0.8486        382        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:03<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:58<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.895      0.813      0.897      0.626\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      5.14G     0.6263      0.354     0.8364        215        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:03<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:15<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.899      0.809        0.9       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      5.14G      0.614     0.3471      0.834        182        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:58<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:24<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.896      0.828      0.908      0.643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      5.14G     0.5952      0.335     0.8303        118        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:57<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:37<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.901      0.816      0.906      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      5.16G     0.5846     0.3294     0.8265        194        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:15<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:47<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141        0.9       0.82      0.902      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      5.15G     0.5711     0.3215     0.8253        216        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:01<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:27<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.903      0.808      0.895      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      5.14G      0.561     0.3142     0.8242        176        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:58<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:11<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.898      0.821      0.905      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      5.16G     0.5487     0.3091      0.821        174        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:59<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:00<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141        0.9      0.817      0.902       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      5.16G     0.5379     0.3008     0.8185        166        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:56<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:58<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.904       0.82      0.903      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      5.14G     0.5295     0.2975     0.8156        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [02:59<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:00<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.895      0.813      0.899      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      5.16G     0.5163      0.289     0.8144        226        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [03:02<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:57<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.896      0.823      0.906      0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 2.206 hours.\n",
      "Optimizer stripped from models\\yolo\\yolov8s_mot17_det4\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from models\\yolo\\yolov8s_mot17_det4\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating models\\yolo\\yolov8s_mot17_det4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.27 ðŸš€ Python-3.11.8 torch-2.2.1 CUDA:0 (NVIDIA GeForce GTX 1070, 8192MiB)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [01:25<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.896      0.823      0.906      0.649\n",
      "Speed: 0.1ms preprocess, 5.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mmodels\\yolo\\yolov8s_mot17_det4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model=YOLO('yolov8s.pt')\n",
    "\n",
    "epochs=30\n",
    "batch_size=-1\n",
    "img_size=640\n",
    "project_name='models/yolo'\n",
    "name='yolov8s_mot17_det'\n",
    "\n",
    "\n",
    "results=model.train(\n",
    "    data=yolo_yaml_path,\n",
    "    epochs=epochs,\n",
    "    batch=batch_size,\n",
    "    imgsz=img_size,\n",
    "    project=project_name,\n",
    "    name=name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20b11811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv8 :\n",
    "    def __init__ (self ,model_path):\n",
    "        self . model = YOLO ( model_path )\n",
    "    def detect (self , source_img ):\n",
    "        results = self.model.predict(source_img,verbose = False )[0]\n",
    "        bboxes = results.boxes.xywh.cpu().numpy()\n",
    "        bboxes [:, :2] = bboxes [:, :2] - ( bboxes [:, 2:] / 2)\n",
    "        scores = results.boxes.conf.cpu().numpy()\n",
    "        class_ids = results.boxes.cls.cpu().numpy()\n",
    "        return bboxes , scores , class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2f5ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'deep_sort'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/wjnwjn59/deep_sort.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b7160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort.deep_sort import nn_matching\n",
    "from deep_sort.deep_sort.detection import Detection\n",
    "from deep_sort.deep_sort.tracker import Tracker\n",
    "from deep_sort.tools import generate_detections as gdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3fdf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSORT :\n",
    "    def __init__ (self ,model_path ='resources/networks/mars-small128.pb',\n",
    "                  max_cosine_distance = 0.7,\n",
    "                  nn_budget = None ,\n",
    "                  classes =['objects']\n",
    "                  ):\n",
    "        self . encoder = gdet . create_box_encoder ( model_path , batch_size =1)\n",
    "        self . metric = nn_matching . NearestNeighborDistanceMetric ('cosine',max_cosine_distance , nn_budget )\n",
    "        self . tracker = Tracker ( self . metric )\n",
    "        key_list = []\n",
    "        val_list = []\n",
    "        for ID , class_name in enumerate ( classes ):\n",
    "            key_list . append (ID)\n",
    "            val_list . append ( class_name )\n",
    "        self . key_list = key_list\n",
    "        self . val_list = val_list\n",
    "    \n",
    "    def tracking (self , origin_frame , bboxes , scores , class_ids ):\n",
    "        features = self . encoder ( origin_frame , bboxes )\n",
    "        detections = [ Detection (bbox , score , class_id , feature )\n",
    "        for bbox , score , class_id , feature in zip(bboxes ,scores ,class_ids ,features )]\n",
    "        self . tracker . predict ()\n",
    "        self . tracker . update ( detections )\n",
    "\n",
    "        tracked_bboxes = []\n",
    "        for track in self . tracker . tracks :\n",
    "            if not track . is_confirmed () or track . time_since_update > 5:\n",
    "                continue\n",
    "            bbox = track . to_tlbr ()\n",
    "            class_id = track . get_class ()\n",
    "            conf_score = track . get_conf_score ()\n",
    "            tracking_id = track . track_id\n",
    "            tracked_bboxes . append (bbox . tolist () + [ class_id , conf_score , tracking_id ])\n",
    "\n",
    "        tracked_bboxes = np. array ( tracked_bboxes )\n",
    "        return tracked_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24593928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detection(img,bboxes,scores,class_ids,ids,classes=['object'],mask_alpha=0.3):\n",
    "    height,width=img.shape[:2]\n",
    "    np.random.seed(0)\n",
    "    rng=np.random.default_rng(3)\n",
    "    colors=rng.uniform(0,255,size=(len(classes),3))\n",
    "    mask_img=img.copy()\n",
    "    det_img=img.copy()\n",
    "    size=min([height,width])*0.0006\n",
    "    text_thickness=int(min([height,width])*0.001)\n",
    "\n",
    "    for bbox,score,class_id,id_ in zip(bboxes,scores,class_ids,ids):\n",
    "        color=colors[class_id]\n",
    "        x1,y1,x2,y2=bbox.astype(int)\n",
    "\n",
    "        cv2.rectangle(det_img,(x1,y1),(x2,y2),color,2)\n",
    "        cv2.rectangle(mask_img,(x1,y1),(x2,y2),color,-1)\n",
    "        label=classes[class_id]\n",
    "        caption=f'{label} {int(score*100)}% ID: {id_}'\n",
    "        (tw,th),_=cv2.getTextSize(text=caption,fontFace=cv2.FONT_HERSHEY_SIMPLEX,fontScale=size,thickness=text_thickness)\n",
    "        th=int(th*1.2)\n",
    "        cv2 . rectangle ( det_img , (x1 , y1), (x1 + tw , y1 - th), color , -1)\n",
    "        cv2 . rectangle ( mask_img , (x1 , y1), (x1 + tw , y1 - th), color , -1)\n",
    "        cv2 . putText ( det_img , caption , (x1 , y1),\n",
    "                       cv2 . FONT_HERSHEY_SIMPLEX , size ,\n",
    "                       (255 , 255 , 255) ,\n",
    "                       text_thickness , cv2 . LINE_AA )\n",
    "        cv2 . putText ( mask_img , caption , (x1 , y1),\n",
    "                       cv2 . FONT_HERSHEY_SIMPLEX , size ,(255 , 255 , 255) ,\n",
    "                       text_thickness , cv2 . LINE_AA )\n",
    "    return cv2. addWeighted ( mask_img , mask_alpha , det_img , 1 - mask_alpha , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54fa1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_tracking ( video_path , detector , tracker ,is_save_result =False , save_dir ='tracking_results'):\n",
    "    cap = cv2. VideoCapture ( video_path )\n",
    "    width = int(cap.get(cv2. CAP_PROP_FRAME_WIDTH ))\n",
    "    height = int (cap. get(cv2. CAP_PROP_FRAME_HEIGHT ))\n",
    "    if is_save_result :\n",
    "        os. makedirs ( save_dir , exist_ok = True )\n",
    "        # Get the video properties\n",
    "        fps = int(cap.get (cv2. CAP_PROP_FPS ))\n",
    "\n",
    "        # Define the codec and create the video writer\n",
    "        fourcc = cv2 . VideoWriter_fourcc (* 'MJPG')\n",
    "        save_result_name = 'output_video.avi'\n",
    "        save_result_path = os. path . join ( save_dir , save_result_name )\n",
    "        out = cv2. VideoWriter ( save_result_path , fourcc , fps , (width , height ))\n",
    "    \n",
    "    all_tracking_results = []\n",
    "    tracked_ids = np. array ([] , dtype =np. int32 )\n",
    "    while True :\n",
    "        ret , frame = cap. read ()\n",
    "        if not ret:\n",
    "            break\n",
    "        detector_results = detector . detect ( frame )\n",
    "        bboxes , scores , class_ids = detector_results\n",
    "        tracker_pred = tracker .tracking (origin_frame =frame ,bboxes =bboxes ,scores =scores ,class_ids = class_ids)\n",
    "\n",
    "        if tracker_pred . size > 0:\n",
    "            bboxes = tracker_pred [:, :4]\n",
    "            class_ids = tracker_pred [:, 4]. astype (int )\n",
    "            conf_scores = tracker_pred [:, 5]\n",
    "            tracking_ids = tracker_pred [:, 6]. astype (int)\n",
    "\n",
    "        # Get new tracking IDs\n",
    "            new_ids = np. setdiff1d ( tracking_ids , tracked_ids )\n",
    "\n",
    "        # Store new tracking IDs\n",
    "            tracked_ids = np. concatenate (( tracked_ids , new_ids ))\n",
    "            result_img = draw_detection (img =frame ,bboxes =bboxes ,scores = conf_scores ,class_ids = class_ids ,ids = tracking_ids)\n",
    "        else :\n",
    "            result_img = frame\n",
    "        all_tracking_results . append ( tracker_pred )\n",
    "        if is_save_result == 1:\n",
    "            out . write ( result_img )\n",
    "        # Break the loop if â€™qâ€™ is pressed\n",
    "        if cv2. waitKey (25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Release video capture\n",
    "    cap . release ()\n",
    "    if is_save_result :\n",
    "        out . release ()\n",
    "        cv2 . destroyAllWindows ()\n",
    "    return all_tracking_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a6f982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model_path = 'models\\yolo\\yolov8s_mot17_det4\\weights\\\\best.pt'\n",
    "\n",
    "detector = YOLOv8 ( yolo_model_path )\n",
    "tracker = DeepSORT ()\n",
    "video_path = 'video.mp4'\n",
    "all_tracking_results = video_tracking (video_path ,detector ,tracker ,is_save_result = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeef0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import os\n",
    "\n",
    "# Input video path\n",
    "output_video_path = 'tracking_results/output_video.avi'\n",
    "\n",
    "# Compressed video path\n",
    "compressed_path = 'tracking_results/result_compressed.mp4'\n",
    "\n",
    "os.system(f\"ffmpeg -i {output_video_path} -vcodec libx264 {compressed_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
